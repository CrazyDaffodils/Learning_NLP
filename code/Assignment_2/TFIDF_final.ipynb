{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "12bd1e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b823522",
   "metadata": {},
   "source": [
    "### Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "78912414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 83032: expected 6 fields, saw 7\\n'\n",
      "b'Skipping line 154657: expected 6 fields, saw 7\\n'\n",
      "b'Skipping line 323916: expected 6 fields, saw 7\\n'\n",
      "/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data.tsv', sep='\\t',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7156e816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133273</td>\n",
       "      <td>213221</td>\n",
       "      <td>213222.0</td>\n",
       "      <td>How is the life of a math student? Could you d...</td>\n",
       "      <td>Which level of prepration is enough for the ex...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>402555</td>\n",
       "      <td>536040</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>How do I control my horny emotions?</td>\n",
       "      <td>How do you control your horniness?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360472</td>\n",
       "      <td>364011</td>\n",
       "      <td>490273.0</td>\n",
       "      <td>What causes stool color to change to yellow?</td>\n",
       "      <td>What can cause stool to come out as little balls?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150662</td>\n",
       "      <td>155721</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>What can one do after MBBS?</td>\n",
       "      <td>What do i do after my MBBS ?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183004</td>\n",
       "      <td>279958</td>\n",
       "      <td>279959.0</td>\n",
       "      <td>Where can I find a power outlet for my laptop ...</td>\n",
       "      <td>Would a second airport in Sydney, Australia be...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1      qid2  \\\n",
       "0  133273  213221  213222.0   \n",
       "1  402555  536040  536041.0   \n",
       "2  360472  364011  490273.0   \n",
       "3  150662  155721    7256.0   \n",
       "4  183004  279958  279959.0   \n",
       "\n",
       "                                           question1  \\\n",
       "0  How is the life of a math student? Could you d...   \n",
       "1                How do I control my horny emotions?   \n",
       "2       What causes stool color to change to yellow?   \n",
       "3                        What can one do after MBBS?   \n",
       "4  Where can I find a power outlet for my laptop ...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  Which level of prepration is enough for the ex...           0.0  \n",
       "1                 How do you control your horniness?           1.0  \n",
       "2  What can cause stool to come out as little balls?           0.0  \n",
       "3                       What do i do after my MBBS ?           1.0  \n",
       "4  Would a second airport in Sydney, Australia be...           0.0  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "66b11bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 363192 entries, 0 to 363191\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            363192 non-null  object \n",
      " 1   qid1          363192 non-null  object \n",
      " 2   qid2          363185 non-null  float64\n",
      " 3   question1     363181 non-null  object \n",
      " 4   question2     363180 non-null  object \n",
      " 5   is_duplicate  363180 non-null  float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1bacfd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows with missing entries in queries, responses or labels\n",
    "df = df.dropna(axis=0, subset=('question1','question2','is_duplicate' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d3ef301a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 363177 entries, 0 to 363191\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            363177 non-null  object \n",
      " 1   qid1          363177 non-null  object \n",
      " 2   qid2          363177 non-null  float64\n",
      " 3   question1     363177 non-null  object \n",
      " 4   question2     363177 non-null  object \n",
      " 5   is_duplicate  363177 non-null  float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 19.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4660db93",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d7d36615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#lower casing\n",
    "def lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "#remove numbers\n",
    "def remove_numbers(text):\n",
    "    output = re.sub(r'\\d+', '', text)\n",
    "    return output\n",
    "\n",
    "# remove punctuation\n",
    "import string\n",
    "def remove_punctuation(text):\n",
    "    text_p = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_p\n",
    "\n",
    "#tokenize text\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    words = word_tokenize(text)\n",
    "    return words\n",
    "\n",
    "#remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    filtered_words = [word for word in text if word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "#remove single character tokens\n",
    "\n",
    "def remove_single_characters(text):\n",
    "    filtered_words = [word for word in text if len(word) > 1]\n",
    "    return filtered_words\n",
    "\n",
    "#stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    stemmed = [stemmer.stem(word) for word in text]\n",
    "    return stemmed\n",
    "\n",
    "# Lemmatize with POS Tag\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemmatized = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in text]\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3cd7bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def preprocess(self,df_column, steps):\n",
    "        self.df_column = df_column\n",
    "        self.steps = steps\n",
    "    \n",
    "        if 'lower_case' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: lower_case(x))\n",
    "        \n",
    "        if 'remove_numbers' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: remove_numbers(x))\n",
    "        \n",
    "        if 'remove_punctuation' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: remove_punctuation(x))           \n",
    "        \n",
    "        if 'tokenize' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: tokenize(x))\n",
    "        \n",
    "        if 'stopwords' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: remove_stopwords(x))\n",
    "            \n",
    "        if 'single_characters' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: remove_single_characters(x))\n",
    "        \n",
    "        if 'stemming' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: stem_words(x))\n",
    "            \n",
    "        if 'lemmatize' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: lemmatize(x))    \n",
    "            \n",
    "        return self.df_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d8ba2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b522311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = ['lower_case','remove_numbers','remove_punctuation',\n",
    "        'tokenize','stopwords','single_characters','stemming']\n",
    "processor = Preprocessor()\n",
    "df['question1'] = processor.preprocess(df['question1'] ,steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "32966a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question2'] = processor.preprocess(df['question2'] ,steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bdb147fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 363177 entries, 0 to 363176\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   index         363177 non-null  int64  \n",
      " 1   id            363177 non-null  object \n",
      " 2   qid1          363177 non-null  object \n",
      " 3   qid2          363177 non-null  float64\n",
      " 4   question1     363177 non-null  object \n",
      " 5   question2     363177 non-null  object \n",
      " 6   is_duplicate  363177 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 19.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f91c78",
   "metadata": {},
   "source": [
    "### Sentence Matching using TF-IDF weighting - implementation from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8caf547a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50010"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a vocabulary list from tokens in responses\n",
    "q2vocab = df['question2'].tolist()\n",
    "q2vocab = [item for sublist in q2vocab for item in sublist]\n",
    "q2vocab = list(set(q2vocab))\n",
    "len(q2vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "33e58f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dropoff', [396539.0]), ('upris', [354113.0, 363877.0, 1005.0, 414734.0])]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dictionary - word in vocabulary: list of response ids (q2id) it is found in\n",
    "Word_Doc_ids = {}\n",
    "for word in q2vocab:\n",
    "    Word_Doc_ids[word] = []\n",
    "for i in range(len(df)):\n",
    "    for word in df.loc[i,'question2']:\n",
    "        Word_Doc_ids[word].append(df.loc[i,'qid2'])\n",
    "\n",
    "#create set to drop duplicate values of doc_ids\n",
    "for word in q2vocab:\n",
    "    Word_Doc_ids[word] = list(set(Word_Doc_ids[word]))\n",
    "    \n",
    "    \n",
    "list(Word_Doc_ids.items())[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "03d6a463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique responses: 273121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('i∧', 11.824537664272047),\n",
       " ('remedi', 7.468955891006257),\n",
       " ('assuar', 11.824537664272047),\n",
       " ('dropoff', 11.824537664272047),\n",
       " ('upris', 10.908268900119985)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create Inverse Document_frequency (IDF) dictionary - word in vocabulary : IDF\n",
    "#use idf formula as per sklearn implementation - for smoothing add 1 to numerator and denominator\n",
    "\n",
    "N = df['qid2'].nunique()\n",
    "print('Number of unique responses: {}'.format(N))\n",
    "\n",
    "IDF = {}\n",
    "for word in Word_Doc_ids.keys():\n",
    "    IDF[word] = np.log((1+N/(len(Word_Doc_ids[word]) +1))+1)\n",
    "list(IDF.items())[:5]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a236517c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(213222.0, ['level', 'preprat', 'enough', 'exam', 'jlpt']),\n",
       " (536041.0, ['control', 'horni'])]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary of list of words in each response - q2id : words\n",
    "doc_words = dict(zip(df['qid2'],df['question2']))\n",
    "\n",
    "list(doc_words.items())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9ad6f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to calculate  norm - to apply 'l1' or 'l2' normalization for calculation of term frequency\n",
    "\n",
    "def norm(list_of_words, normalization_method = 'l1'):\n",
    "    word_vec = np.array([list_of_words.count(word) for word in set(list_of_words)])\n",
    "    if normalization_method == 'l1':\n",
    "        norm = np.linalg.norm(word_vec,ord=1)\n",
    "    else:\n",
    "        norm = np.linalg.norm(word_vec, ord=2)\n",
    "    return norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e9531dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary where keys are words in the vocabulary, \n",
    "#values are dictionary of key:values as q2id : term frequency for corresponding word\n",
    "#nested dictionary - word: {{q2id1: tf}, {q2id2: tf}, ....}\n",
    "#use 'l1' norm to normalize term frequency\n",
    "\n",
    "inverted_tf_l1 = {}\n",
    "for word in q2vocab:\n",
    "    word_tf = {}\n",
    "    for doc in Word_Doc_ids[word]:\n",
    "        tf = doc_words[doc].count(word)/norm(doc_words[doc],'l1')\n",
    "        word_tf[doc] = tf\n",
    "    inverted_tf_l1[word] = word_tf   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a390f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use 'l2' norm to normalize term frequency\n",
    "\n",
    "inverted_tf_l2 = {}\n",
    "for word in q2vocab:\n",
    "    word_tf = {}\n",
    "    for doc in Word_Doc_ids[word]:\n",
    "        tf = doc_words[doc].count(word)/norm(doc_words[doc],'l2')\n",
    "        word_tf[doc] = tf\n",
    "    inverted_tf_l2[word] = word_tf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f6e05",
   "metadata": {},
   "source": [
    "#### Creating inverted file for retreiving tfidf values - term frequencies normalized by either 'l1' or 'l2' norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "be2b845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary where keys are words in the vocab, \n",
    "#values are dictinary of key:values as doc_id:tfidf for corresponding word\n",
    "#nested dictionary - word: {{doc_id1: tf}, {doc_id2: tf}, ....}\n",
    "\n",
    "inverted_tfidf_l1 = {}\n",
    "for word in q2vocab:\n",
    "    doc_tfidfs = []\n",
    "    for tup in list(inverted_tf_l1[word].items()):\n",
    "        tup = list(tup)\n",
    "        tfidf = tup[1]*IDF[word]\n",
    "        tup[1] = tfidf\n",
    "        doc_tfidfs.append(tup)\n",
    "    inverted_tfidf_l1[word] = doc_tfidfs  \n",
    "    \n",
    "    \n",
    "inverted_tfidf_l2 = {}\n",
    "for word in q2vocab:\n",
    "    doc_tfidfs = []\n",
    "    for tup in list(inverted_tf_l2[word].items()):\n",
    "        tup = list(tup)\n",
    "        tfidf = tup[1]*IDF[word]\n",
    "        tup[1] = tfidf\n",
    "        doc_tfidfs.append(tup)\n",
    "    inverted_tfidf_l2[word] = doc_tfidfs     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4cc636be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(inverted_tfidf_l1)):\n",
    "    inverted_tfidf_l1[q2vocab[i]] = {x[0]:x[1] for x in inverted_tfidf_l1[q2vocab[i]]}\n",
    "    \n",
    "for i in range(len(inverted_tfidf_l2)):\n",
    "    inverted_tfidf_l2[q2vocab[i]] = {x[0]:x[1] for x in inverted_tfidf_l2[q2vocab[i]]}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4827c290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dropoff', {396539.0: 1.9707562773786744}),\n",
       " ('upris',\n",
       "  {354113.0: 1.818044816686664,\n",
       "   363877.0: 1.3635336125149982,\n",
       "   1005.0: 2.1816537800239972,\n",
       "   414734.0: 1.0908268900119986})]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(inverted_tfidf_l1.items())[3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8a6c3ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>question1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536040</td>\n",
       "      <td>[control, horni, emot]</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>[control, horni]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155721</td>\n",
       "      <td>[one, mbb]</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>[mbb]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147570</td>\n",
       "      <td>[best, self, help, book, read, chang, life]</td>\n",
       "      <td>787.0</td>\n",
       "      <td>[top, self, help, book, read]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71243</td>\n",
       "      <td>[hillari, clinton, polici, toward, india, beco...</td>\n",
       "      <td>177376.0</td>\n",
       "      <td>[hilari, clinton, polici, toward, india, becom...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22332</td>\n",
       "      <td>[best, book, studi, tensor, gener, rel, basic]</td>\n",
       "      <td>22333.0</td>\n",
       "      <td>[best, book, tensor, calculu]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid1                                          question1      qid2  \\\n",
       "0  536040                             [control, horni, emot]  536041.0   \n",
       "1  155721                                         [one, mbb]    7256.0   \n",
       "2  147570        [best, self, help, book, read, chang, life]     787.0   \n",
       "3   71243  [hillari, clinton, polici, toward, india, beco...  177376.0   \n",
       "4   22332     [best, book, studi, tensor, gener, rel, basic]   22333.0   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0                                   [control, horni]           1.0  \n",
       "1                                              [mbb]           1.0  \n",
       "2                      [top, self, help, book, read]           1.0  \n",
       "3  [hilari, clinton, polici, toward, india, becom...           1.0  \n",
       "4                      [best, book, tensor, calculu]           1.0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe of top 100 queries that have label = 1\n",
    "queries = df[df['is_duplicate'] == 1][:100]\n",
    "queries = queries[['qid1','question1','qid2','question2', 'is_duplicate']]\n",
    "queries = queries.reset_index(drop=True)\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "aea9278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to retrieve matching responses against query\n",
    "from collections import Counter\n",
    "def ranked_docs(query, inverted_file):\n",
    "    counter_objects = []\n",
    "    for word in query:\n",
    "        if word in inverted_file.keys():\n",
    "            counter_objects.append(Counter(inverted_file[word]))\n",
    "            combined = sum(counter_objects,Counter())\n",
    "            ranked_docs = sorted(combined, key = combined.get, reverse=True)\n",
    "    return ranked_docs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "19bff53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>question1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>top5_pred_l1</th>\n",
       "      <th>top2_pred_l1</th>\n",
       "      <th>top5_pred_l2</th>\n",
       "      <th>top2_pred_l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536040</td>\n",
       "      <td>[control, horni, emot]</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>[control, horni]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155721</td>\n",
       "      <td>[one, mbb]</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>[mbb]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147570</td>\n",
       "      <td>[best, self, help, book, read, chang, life]</td>\n",
       "      <td>787.0</td>\n",
       "      <td>[top, self, help, book, read]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71243</td>\n",
       "      <td>[hillari, clinton, polici, toward, india, beco...</td>\n",
       "      <td>177376.0</td>\n",
       "      <td>[hilari, clinton, polici, toward, india, becom...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22332</td>\n",
       "      <td>[best, book, studi, tensor, gener, rel, basic]</td>\n",
       "      <td>22333.0</td>\n",
       "      <td>[best, book, tensor, calculu]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid1                                          question1      qid2  \\\n",
       "0  536040                             [control, horni, emot]  536041.0   \n",
       "1  155721                                         [one, mbb]    7256.0   \n",
       "2  147570        [best, self, help, book, read, chang, life]     787.0   \n",
       "3   71243  [hillari, clinton, polici, toward, india, beco...  177376.0   \n",
       "4   22332     [best, book, studi, tensor, gener, rel, basic]   22333.0   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0                                   [control, horni]           1.0   \n",
       "1                                              [mbb]           1.0   \n",
       "2                      [top, self, help, book, read]           1.0   \n",
       "3  [hilari, clinton, polici, toward, india, becom...           1.0   \n",
       "4                      [best, book, tensor, calculu]           1.0   \n",
       "\n",
       "   top5_pred_l1  top2_pred_l1  top5_pred_l2  top2_pred_l2  \n",
       "0           1.0           0.0           1.0           1.0  \n",
       "1           1.0           0.0           1.0           0.0  \n",
       "2           0.0           0.0           1.0           1.0  \n",
       "3           0.0           0.0           1.0           0.0  \n",
       "4           0.0           0.0           1.0           0.0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use inverted_tfidf_l1 or inverted_tfidf_l2 to retrieve top5 and top2 matching responses against queries\n",
    "for i in range(len(queries)):\n",
    "    query = queries.loc[i,'question1']\n",
    "    ranked = ranked_docs(query, inverted_tfidf_l1)\n",
    "    if queries.loc[i,'qid2'] in ranked[:2]:\n",
    "        queries.loc[i,'top5_pred_l1'] = 1.0\n",
    "        queries.loc[i,'top2_pred_l1'] = 1.0\n",
    "    elif queries.loc[i,'qid2'] in ranked[:5]:\n",
    "        queries.loc[i,'top5_pred_l1'] = 1.0\n",
    "        queries.loc[i,'top2_pred_l1'] = 0.0\n",
    "    else:\n",
    "        queries.loc[i,'top5_pred_l1'] = 0.0\n",
    "        queries.loc[i,'top2_pred_l1'] = 0.0\n",
    "    \n",
    "\n",
    "for i in range(len(queries)):\n",
    "    query = queries.loc[i,'question1']\n",
    "    ranked = ranked_docs(query, inverted_tfidf_l2)\n",
    "    if queries.loc[i,'qid2'] in ranked[:2]:\n",
    "        queries.loc[i,'top5_pred_l2'] = 1.0\n",
    "        queries.loc[i,'top2_pred_l2'] = 1.0\n",
    "    elif queries.loc[i,'qid2'] in ranked[:5]:\n",
    "        queries.loc[i,'top5_pred_l2'] = 1.0\n",
    "        queries.loc[i,'top2_pred_l2'] = 0.0\n",
    "    else:\n",
    "        queries.loc[i,'top5_pred_l2'] = 0.0\n",
    "        queries.loc[i,'top2_pred_l2'] = 0.0    \n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e80fb2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133273</td>\n",
       "      <td>213221</td>\n",
       "      <td>213222.0</td>\n",
       "      <td>How is the life of a math student? Could you d...</td>\n",
       "      <td>Which level of prepration is enough for the ex...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>402555</td>\n",
       "      <td>536040</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>How do I control my horny emotions?</td>\n",
       "      <td>How do you control your horniness?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360472</td>\n",
       "      <td>364011</td>\n",
       "      <td>490273.0</td>\n",
       "      <td>What causes stool color to change to yellow?</td>\n",
       "      <td>What can cause stool to come out as little balls?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150662</td>\n",
       "      <td>155721</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>What can one do after MBBS?</td>\n",
       "      <td>What do i do after my MBBS ?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183004</td>\n",
       "      <td>279958</td>\n",
       "      <td>279959.0</td>\n",
       "      <td>Where can I find a power outlet for my laptop ...</td>\n",
       "      <td>Would a second airport in Sydney, Australia be...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1      qid2  \\\n",
       "0  133273  213221  213222.0   \n",
       "1  402555  536040  536041.0   \n",
       "2  360472  364011  490273.0   \n",
       "3  150662  155721    7256.0   \n",
       "4  183004  279958  279959.0   \n",
       "\n",
       "                                           question1  \\\n",
       "0  How is the life of a math student? Could you d...   \n",
       "1                How do I control my horny emotions?   \n",
       "2       What causes stool color to change to yellow?   \n",
       "3                        What can one do after MBBS?   \n",
       "4  Where can I find a power outlet for my laptop ...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  Which level of prepration is enough for the ex...           0.0  \n",
       "1                 How do you control your horniness?           1.0  \n",
       "2  What can cause stool to come out as little balls?           0.0  \n",
       "3                       What do i do after my MBBS ?           1.0  \n",
       "4  Would a second airport in Sydney, Australia be...           0.0  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dc3d8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retreive_unprocessed_question(question_qid, question_type):\n",
    "    if question_type == 'query':\n",
    "        unprocessed_question = unprocessed_df.loc[unprocessed_df['qid1']==question_qid, 'question1'].iloc[0]\n",
    "    else:\n",
    "        unprocessed_question = unprocessed_df.loc[unprocessed_df['qid2']==question_qid, 'question2'].iloc[0]\n",
    "    \n",
    "    return unprocessed_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0f2ccf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6249e9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What do i do after my MBBS ?'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_index = 1\n",
    "#query = queries.loc[query_index,'question1' ]\n",
    "response_qid = queries.loc[query_index,'qid2']\n",
    "unprocessed_query = retreive_unprocessed_question(response_qid,'response')\n",
    "unprocessed_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9e8e0b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to view matching responses\n",
    "def view_ranked_responses(query_index,number_of_responses, normalization_method):\n",
    "    \n",
    "    query = queries.loc[query_index,'question1' ]\n",
    "    query_qid = queries.loc[query_index,'qid1']\n",
    "    actual_response_id = queries.loc[query_index,'qid2']\n",
    "    \n",
    "    \n",
    "    if normalization_method == 'l1':\n",
    "        top_responses = ranked_docs(query, inverted_tfidf_l1)[:number_of_responses]\n",
    "    else:\n",
    "        top_responses = ranked_docs(query, inverted_tfidf_l2)[:number_of_responses]\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    print(color.BOLD+'Sentence matching with TF-IDF method - implementation from scratch...'+color.END) \n",
    "    print()\n",
    "    \n",
    "    print(color.BOLD+'Query'+color.END)\n",
    "    print(color.RED+retreive_unprocessed_question(query_qid,'query')+color.END)\n",
    "    print()\n",
    "    print(color.BOLD+'Ground truth (actual) matching response'+color.END)\n",
    "    print(color.CYAN +retreive_unprocessed_question(actual_response_id,'response')+color.END)\n",
    "    print()\n",
    "    print(color.BOLD+'Top {} matched responses by TFIDF method, {} normalization'.format(number_of_responses,normalization_method)+color.END)\n",
    "    for response_id in top_responses:\n",
    "        if response_id == actual_response_id:\n",
    "            print(color.CYAN+retreive_unprocessed_question(response_id,'response')+color.END)\n",
    "        else:\n",
    "            print(retreive_unprocessed_question(response_id,'response'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0fe436b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSentence matching with TF-IDF method - implementation from scratch...\u001b[0m\n",
      "\n",
      "\u001b[1mQuery\u001b[0m\n",
      "\u001b[91mCould I buy a civilianized version of a fighter jet?\u001b[0m\n",
      "\n",
      "\u001b[1mGround truth (actual) matching response\u001b[0m\n",
      "\u001b[96mCan I buy a fighter jet?\u001b[0m\n",
      "\n",
      "\u001b[1mTop 5 matched responses by TFIDF method, l1 normalization\u001b[0m\n",
      "Who are the z fighters?\n",
      "\u001b[96mCan I buy a fighter jet?\u001b[0m\n",
      "Can a civilian buy a fighter jet if he is rich enough?\n",
      "What should I buy with $800?\n",
      "How do I buy Jets from USa?\n"
     ]
    }
   ],
   "source": [
    "view_ranked_responses(76,5,'l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b6b30800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " L1-norm TF-IDF - accuracy of retriving correct response in top 2 ranked responses : 16.0 %\n",
      " L1-norm TF-IDF - accuracy of retriving correct response in top 5 ranked responses : 30.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "top2_l1 = accuracy_score(queries['is_duplicate'],queries['top2_pred_l1'])\n",
    "top5_l1 = accuracy_score(queries['is_duplicate'],queries['top5_pred_l1'])\n",
    "print(' L1-norm TF-IDF - accuracy of retriving correct response in top 2 ranked responses : {} %'.format(top2_l1*100))\n",
    "print(' L1-norm TF-IDF - accuracy of retriving correct response in top 5 ranked responses : {} %'.format(top5_l1*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8e495fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " L2-norm TF-IDF - accuracy of retriving correct response in top 2 ranked responses : 47.0 %\n",
      " L2-norm TF-IDF - accuracy of retriving correct response in top 5 ranked responses : 58.0 %\n"
     ]
    }
   ],
   "source": [
    "top2_l2 = accuracy_score(queries['is_duplicate'],queries['top2_pred_l2'])\n",
    "top5_l2 = accuracy_score(queries['is_duplicate'],queries['top5_pred_l2'])\n",
    "print(' L2-norm TF-IDF - accuracy of retriving correct response in top 2 ranked responses : {} %'.format(top2_l2*100))\n",
    "print(' L2-norm TF-IDF - accuracy of retriving correct response in top 5 ranked responses : {:.1f} %'.format(top5_l2*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71709862",
   "metadata": {},
   "source": [
    "### Sentence matching with TFIDF -  sklearn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "347d1c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df[['qid2','question2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c45f612b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-212-0c4882f2a7fa>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus.drop_duplicates(subset='qid2', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "corpus.drop_duplicates(subset='qid2', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "42a07a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn tfidf - l1 normalization method\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "train_questions = list(corpus['question2'])\n",
    "query_questions = list(queries['question1'])\n",
    "\n",
    "def dummy(text):\n",
    "    return text\n",
    "\n",
    "tf1 = TfidfVectorizer(tokenizer=dummy,preprocessor=dummy, lowercase=False, norm='l1')\n",
    "X_train = tf1.fit_transform(train_questions)\n",
    "X_test = tf1.transform(query_questions)\n",
    "\n",
    "matched = np.array((X_test@X_train.T).todense())\n",
    "matched_sorted = np.zeros(matched.shape, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1a0e365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sktop2_l1 = []\n",
    "sktop5_l1 = []\n",
    "\n",
    "for i in range(matched.shape[0]):\n",
    "    matched_sorted[i,:] = matched[i,:].argsort()[::-1]\n",
    "    top2ind = matched_sorted[i,:2]\n",
    "    top5ind = matched_sorted[i,:5]\n",
    "    top2docs = [corpus.iloc[c,0] for c in top2ind]\n",
    "    top5docs = [corpus.iloc[c,0] for c in top5ind]\n",
    "    if queries.iloc[i,2] in top2docs:\n",
    "        sktop2_l1.append(1)\n",
    "    else:\n",
    "        sktop2_l1.append(0)\n",
    "    if queries.iloc[i,2] in top5docs:\n",
    "        sktop5_l1.append(1)\n",
    "    else:\n",
    "        sktop5_l1.append(0)\n",
    "\n",
    "queries['sktop2_l1'] = sktop2_l1\n",
    "queries['sktop5_l1'] = sktop5_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4036eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf2 = TfidfVectorizer(tokenizer=dummy,preprocessor=dummy, lowercase=False, norm='l2')\n",
    "X_train2 = tf2.fit_transform(train_questions)\n",
    "X_test2 = tf2.transform(query_questions)\n",
    "matched2 = np.array((X_test2@X_train2.T).todense())\n",
    "matched_sorted2 = np.zeros(matched2.shape, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d10508a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sktop2_l2 = []\n",
    "sktop5_l2 = []\n",
    "\n",
    "for i in range(matched2.shape[0]):\n",
    "    matched_sorted2[i,:] = matched2[i,:].argsort()[::-1]\n",
    "    top2ind = matched_sorted2[i,:2]\n",
    "    top5ind = matched_sorted2[i,:5]\n",
    "    top2docs = [corpus.iloc[c,0] for c in top2ind]\n",
    "    top5docs = [corpus.iloc[c,0] for c in top5ind]\n",
    "    if queries.iloc[i,2] in top2docs:\n",
    "        sktop2_l2.append(1)\n",
    "    else:\n",
    "        sktop2_l2.append(0)\n",
    "    if queries.iloc[i,2] in top5docs:\n",
    "        sktop5_l2.append(1)\n",
    "    else:\n",
    "        sktop5_l2.append(0)\n",
    "\n",
    "queries['sktop2_l2'] = sktop2_l2\n",
    "queries['sktop5_l2'] = sktop5_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c6d7c1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn - Accuracy of retreiving correct response in top 2 matched responses - l1 normalization: 16.0\n",
      "Sklearn - Accuracy of retreiving correct response in top 5 matched responses - l1 normalization: 32.0\n"
     ]
    }
   ],
   "source": [
    "sktop2_l1 = accuracy_score(queries['is_duplicate'], queries['sktop2_l1'])\n",
    "sktop5_l1 = accuracy_score(queries['is_duplicate'], queries['sktop5_l1'])\n",
    "print('Sklearn - Accuracy of retreiving correct response in top 2 matched responses - l1 normalization: {}'.format(sktop2_l1*100))\n",
    "print('Sklearn - Accuracy of retreiving correct response in top 5 matched responses - l1 normalization: {}'.format(sktop5_l1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "01df7c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn - Accuracy of retreiving correct response in top 2 matched responses - l2 normalization: 45.0\n",
      "Sklearn - Accuracy of retreiving correct response in top 5 matched responses - l2 normalization: 61.0\n"
     ]
    }
   ],
   "source": [
    "sktop2_l2 = accuracy_score(queries['is_duplicate'], queries['sktop2_l2'])\n",
    "sktop5_l2 = accuracy_score(queries['is_duplicate'], queries['sktop5_l2'])\n",
    "print('Sklearn - Accuracy of retreiving correct response in top 2 matched responses - l2 normalization: {}'.format(sktop2_l2*100))\n",
    "print('Sklearn - Accuracy of retreiving correct response in top 5 matched responses - l2 normalization: {}'.format(sktop5_l2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1a5b6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframes\n",
    "# unprocessed_df.to_pickle('unprocessed_dataframe')\n",
    "# df.to_pickle('text_preprocessed_dataframe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7744aa53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
