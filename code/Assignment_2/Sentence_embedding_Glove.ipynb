{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "12bd1e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b823522",
   "metadata": {},
   "source": [
    "### Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78912414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 83032: expected 6 fields, saw 7\\n'\n",
      "b'Skipping line 154657: expected 6 fields, saw 7\\n'\n",
      "b'Skipping line 323916: expected 6 fields, saw 7\\n'\n",
      "/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data.tsv', sep='\\t',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7156e816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133273</td>\n",
       "      <td>213221</td>\n",
       "      <td>213222.0</td>\n",
       "      <td>How is the life of a math student? Could you d...</td>\n",
       "      <td>Which level of prepration is enough for the ex...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>402555</td>\n",
       "      <td>536040</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>How do I control my horny emotions?</td>\n",
       "      <td>How do you control your horniness?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360472</td>\n",
       "      <td>364011</td>\n",
       "      <td>490273.0</td>\n",
       "      <td>What causes stool color to change to yellow?</td>\n",
       "      <td>What can cause stool to come out as little balls?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150662</td>\n",
       "      <td>155721</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>What can one do after MBBS?</td>\n",
       "      <td>What do i do after my MBBS ?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183004</td>\n",
       "      <td>279958</td>\n",
       "      <td>279959.0</td>\n",
       "      <td>Where can I find a power outlet for my laptop ...</td>\n",
       "      <td>Would a second airport in Sydney, Australia be...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1      qid2  \\\n",
       "0  133273  213221  213222.0   \n",
       "1  402555  536040  536041.0   \n",
       "2  360472  364011  490273.0   \n",
       "3  150662  155721    7256.0   \n",
       "4  183004  279958  279959.0   \n",
       "\n",
       "                                           question1  \\\n",
       "0  How is the life of a math student? Could you d...   \n",
       "1                How do I control my horny emotions?   \n",
       "2       What causes stool color to change to yellow?   \n",
       "3                        What can one do after MBBS?   \n",
       "4  Where can I find a power outlet for my laptop ...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  Which level of prepration is enough for the ex...           0.0  \n",
       "1                 How do you control your horniness?           1.0  \n",
       "2  What can cause stool to come out as little balls?           0.0  \n",
       "3                       What do i do after my MBBS ?           1.0  \n",
       "4  Would a second airport in Sydney, Australia be...           0.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1bacfd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows with missing entries in queries, responses or labels\n",
    "df = df.dropna(axis=0, subset=('question1','question2','is_duplicate' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4660db93",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7d36615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#lower casing\n",
    "def lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "#remove numbers\n",
    "def remove_numbers(text):\n",
    "    output = re.sub(r'\\d+', '', text)\n",
    "    return output\n",
    "\n",
    "# remove punctuation\n",
    "import string\n",
    "def remove_punctuation(text):\n",
    "    text_p = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_p\n",
    "\n",
    "#tokenize text\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    words = word_tokenize(text)\n",
    "    return words\n",
    "\n",
    "#remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    filtered_words = [word for word in text if word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3cd7bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def preprocess(self,df_column, steps):\n",
    "        self.df_column = df_column\n",
    "        self.steps = steps\n",
    "    \n",
    "        if 'lower_case' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: lower_case(x))\n",
    "        \n",
    "        if 'remove_numbers' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: remove_numbers(x))\n",
    "        \n",
    "        if 'remove_punctuation' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: remove_punctuation(x))           \n",
    "        \n",
    "        if 'tokenize' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: tokenize(x))\n",
    "        \n",
    "        if 'stopwords' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: remove_stopwords(x))\n",
    "            \n",
    "        \n",
    "        \n",
    "        return self.df_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8ba2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b522311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = ['lower_case','remove_numbers','remove_punctuation',\n",
    "        'tokenize','stopwords']\n",
    "processor = Preprocessor()\n",
    "df['question1'] = processor.preprocess(df['question1'] ,steps)\n",
    "df['question2'] = processor.preprocess(df['question2'] ,steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bdb147fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 363177 entries, 0 to 363176\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   index         363177 non-null  int64  \n",
      " 1   id            363177 non-null  object \n",
      " 2   qid1          363177 non-null  object \n",
      " 3   qid2          363177 non-null  float64\n",
      " 4   question1     363177 non-null  object \n",
      " 5   question2     363177 non-null  object \n",
      " 6   is_duplicate  363177 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 19.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f91c78",
   "metadata": {},
   "source": [
    "### Sentence Matching using pretrained vectors for Word representation - Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8caf547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download Glove pretrained word vectors and store embeddings in a dictionary\n",
    "embeddings_dict = {}\n",
    "with open('../data/glove.6B.300d.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a75a5a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example vector embedding\n",
    "v = embeddings_dict['king']\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33e58f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>question1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536040</td>\n",
       "      <td>[control, horny, emotions]</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>[control, horniness]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155721</td>\n",
       "      <td>[one, mbbs]</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>[mbbs]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid1                   question1      qid2             question2  \\\n",
       "0  536040  [control, horny, emotions]  536041.0  [control, horniness]   \n",
       "1  155721                 [one, mbbs]    7256.0                [mbbs]   \n",
       "\n",
       "   is_duplicate  \n",
       "0           1.0  \n",
       "1           1.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe of top 100 queries that have label = 1\n",
    "queries = df[df['is_duplicate'] == 1][:100]\n",
    "queries = queries[['qid1','question1','qid2','question2', 'is_duplicate']]\n",
    "queries = queries.reset_index(drop=True)\n",
    "queries.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0dd37122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273121"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = df[['qid2','question2']]\n",
    "responses = responses.drop_duplicates('qid2').reset_index(drop=True)\n",
    "len(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2dee64",
   "metadata": {},
   "source": [
    "#### Sentence embedding - Averaging word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "03d6a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mean_Vectorizer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X):\n",
    "        return self\n",
    "        \n",
    "    def transform(self,embeddings,data):\n",
    "        self.embeddings = embeddings\n",
    "        self.data = data\n",
    "        \n",
    "        #get dimensionality of word embeddings\n",
    "        v = self.embeddings['king']\n",
    "        self.D = v.shape[0]\n",
    "        \n",
    "        #zeros matrix for 'question2' embeddings\n",
    "        X = np.zeros(shape = (len(data),self.D))\n",
    "        \n",
    "        #averaging word representations\n",
    "        for i in range(len(data)):\n",
    "            words = data[i]\n",
    "            vectors = []\n",
    "            for word in words:\n",
    "                try:\n",
    "                    v = self.embeddings[word]\n",
    "                    vectors.append(v)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            vectors = np.array(vectors)\n",
    "            if len(vectors) >0:\n",
    "                sentence_embedding = np.mean(vectors, axis=0).reshape(1,-1)\n",
    "                X[i,:] = sentence_embedding\n",
    "            \n",
    "        return X\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e69b01f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to cosine similarity between each query and all responses. \n",
    "#Rank responses in terms of cosine similarity\n",
    "\n",
    "def cos_sim(vector1,vector2):\n",
    "    cosine_similarity = np.dot(vector1,vector2)/(np.linalg.norm(vector1,ord=2)*np.linalg.norm(vector2,ord=2))\n",
    "    return cosine_similarity\n",
    "\n",
    "#define function to get unprocessed (original) question\n",
    "def retreive_unprocessed_question(question_qid, question_type):\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        question_qid - 'qid' of question\n",
    "        question_type - 'response'  or 'query'\n",
    "    \n",
    "    Returns:\n",
    "        unprocessed_question - original question before text preprocessing\n",
    "    \"\"\"\n",
    "    if question_type == 'query':\n",
    "        unprocessed_question = unprocessed_df.loc[unprocessed_df['qid1']==question_qid, 'question1'].iloc[0]\n",
    "    else:\n",
    "        unprocessed_question = unprocessed_df.loc[unprocessed_df['qid2']==question_qid, 'question2'].iloc[0]\n",
    "    \n",
    "    return unprocessed_question\n",
    "\n",
    "\n",
    "#define function to get/view top 2/5 most matching responses, given a query index\n",
    "def get_matched_responses(query_index, responses_matrix,queries_matrix,number_of_responses, print_results = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        query_index :  0 to 99 - first 100 queries that have label 'is_duplicate' = 1.\n",
    "    \n",
    "        responses_matrix : Matrix of sentence embeddings for unique responses, shape = 273121 x 50\n",
    "    \n",
    "        queries_matrix : Matrix of sentence embeddings for queries, shape = 100 x 50\n",
    "    \n",
    "        number_of_responses : top 2 or top 5 numbers of matching responses against a query\n",
    "    \n",
    "        print_results: If true, prints the unprocessed query, ground truth response and top2 or top5 matching responses obtained by sentence embedding method\n",
    "    \n",
    "    Returns: \n",
    "        matched_responses : list of 'qid2' for top 2 or top 5 matching responses\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    query_qid = queries.loc[query_index,'qid1']\n",
    "    actual_response_id = queries.loc[query_index,'qid2']\n",
    "    \n",
    "    similarities = []\n",
    "    for r in range(len(responses_matrix)):\n",
    "        cosine_sim = cos_sim(queries_matrix[query_index,:],responses_matrix[r,:])\n",
    "        similarities.append(cosine_sim)\n",
    "    similarities = np.array(similarities)\n",
    "    similarities = np.nan_to_num(similarities,nan=-9999) #replace nans with large negative number\n",
    "    sorted_sim = similarities.argsort()[::-1][:number_of_responses]\n",
    "    \n",
    "    matched_responses = []\n",
    "    for response_id in sorted_sim:\n",
    "        response_qid2 = responses.loc[response_id,'qid2']\n",
    "        matched_responses.append(response_qid2)\n",
    "            \n",
    "        \n",
    "    if print_results:\n",
    "        print('Query')\n",
    "        print(retreive_unprocessed_question(query_qid,'query'))\n",
    "        print()\n",
    "        print('Ground truth (actual) response')\n",
    "        print(retreive_unprocessed_question(actual_response_id,'response'))\n",
    "        print()\n",
    "        print('Top {} matching responses'.format(number_of_responses))\n",
    "        for response in matched_responses:\n",
    "            print(retreive_unprocessed_question(response,'response'))\n",
    "    else:        \n",
    "        \n",
    "        return matched_responses \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a236517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = Mean_Vectorizer()\n",
    "responses_mean = mv.transform(embeddings_dict,responses['question2'])\n",
    "queries_mean = mv.transform(embeddings_dict,queries['question1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7cbae2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-924ea8ae829c>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cosine_similarity = np.dot(vector1,vector2)/(np.linalg.norm(vector1,ord=2)*np.linalg.norm(vector2,ord=2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query\n",
      "What can one do after MBBS?\n",
      "\n",
      "Ground truth (actual) response\n",
      "What do i do after my MBBS ?\n",
      "\n",
      "Top 5 matching responses\n",
      "What do i do after my MBBS ?\n",
      "What can I do after my MBBs?\n",
      "What have to Do after MBBS?\n",
      "Is M.B.B.S a good major?\n",
      "Which course should I choose after an MBBS?\n"
     ]
    }
   ],
   "source": [
    "get_matched_responses(1,responses_mean,queries_mean,5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ad6f9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-924ea8ae829c>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cosine_similarity = np.dot(vector1,vector2)/(np.linalg.norm(vector1,ord=2)*np.linalg.norm(vector2,ord=2))\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy for matched responses for all queries - sentence embedding by word vector averaging\n",
    "top2_mean = []\n",
    "top5_mean = []\n",
    "\n",
    "for query_index in range(len(queries)):\n",
    "    actual_response_id = queries.loc[query_index,'qid2']\n",
    "    top5_ranked = get_matched_responses(query_index,responses_mean,queries_mean,5,False)     \n",
    "    if actual_response_id in top5_ranked[:2]:\n",
    "        top2_mean.append(1.0)\n",
    "        top5_mean.append(1.0)\n",
    "    elif actual_response_id in top5_ranked:\n",
    "        top2_mean.append(0.0)\n",
    "        top5_mean.append(1.0)    \n",
    "    else:\n",
    "        top2_mean.append(0.0)\n",
    "        top5_mean.append(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "30c79851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for matched responses in top 2, with averaged word vectors for sentence embedding: 41.0 %\n",
      "Accuracy for matched responses in top 5, with averaged word vectors for sentence embedding: 54.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "top2_mean_acc = accuracy_score(queries['is_duplicate'], top2_mean)\n",
    "top5_mean_acc = (accuracy_score(queries['is_duplicate'],top5_mean))\n",
    "\n",
    "print('Accuracy for matched responses in top 2, with averaged word vectors for sentence embedding: {} %'. format(top2_mean_acc *100))\n",
    "print('Accuracy for matched responses in top 5, with averaged word vectors for sentence embedding: {} %'. format(top5_mean_acc *100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cc739e",
   "metadata": {},
   "source": [
    "### Sentence embedding -  word vectors weighted by TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "42a07a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate IDF for words in responses - sklearn implementation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = list(responses['question2'])\n",
    "\n",
    "\n",
    "tfsk = TfidfVectorizer(tokenizer=None,analyzer=(lambda x: x), preprocessor=None, lowercase=False)\n",
    "X_trainsk = tfsk.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b4ee61a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.82452668023003"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idf = max(tfsk.idf_)\n",
    "max_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "86002712",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordIDF = defaultdict(lambda x: max_idf)\n",
    "wordIDF = {word : tfsk.idf_[i] for word,i in tfsk.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a3238cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66626"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "52afea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zeros matrix for 'question2' embeddings\n",
    "X = np.zeros(shape = (len(responses['question2']),300))        \n",
    "#averaging word representations\n",
    "for i in range(len(responses)):\n",
    "    words = responses['question2'][i]\n",
    "    vectors = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            v = embeddings_dict[word] * wordIDF[word]\n",
    "            vectors.append(v)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    vectors = np.array(vectors)\n",
    "    if len(vectors) >0:\n",
    "        sentence_embedding = np.mean(vectors, axis=0).reshape(1,-1)\n",
    "        X[i,:] = sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "73b29c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDF_weight_vectorizer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X_train):\n",
    "\n",
    "        tf = TfidfVectorizer(tokenizer=None,analyzer=(lambda x: x), preprocessor=None, lowercase=False)\n",
    "        tf.fit(X_train)\n",
    "        max_idf = max(tf.idf_)\n",
    "        \n",
    "        self.word_idf = defaultdict(lambda: max_idf)\n",
    "        self.word_idf = {word : tf.idf_[i] for word,i in tf.vocabulary_.items()}\n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def transform(self,embeddings,data):\n",
    "        self.embeddings = embeddings\n",
    "        self.data = data\n",
    "        \n",
    "        #get dimensionality of word embeddings\n",
    "        v = self.embeddings['king']\n",
    "        self.D = v.shape[0]\n",
    "        \n",
    "        #zeros matrix for 'question2' embeddings\n",
    "        X = np.zeros(shape = (len(data),self.D))\n",
    "        \n",
    "        #averaging word representations\n",
    "        for i in range(len(data)):\n",
    "            words = data[i]\n",
    "            vectors = []\n",
    "            for word in words:\n",
    "                try:\n",
    "                    v = self.embeddings[word] * self.word_idf[word]\n",
    "                    vectors.append(v)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            vectors = np.array(vectors)\n",
    "            if len(vectors) >0:\n",
    "                sentence_embedding = np.mean(vectors, axis=0).reshape(1,-1)\n",
    "                X[i,:] = sentence_embedding\n",
    "            \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8351cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TFIDF_weight_vectorizer()\n",
    "responses_tfidf = tf.fit(list(responses['question2']))\n",
    "responses_tfidf = tf.transform(embeddings_dict,responses['question2'])\n",
    "queries_tfidf = tf.transform(embeddings_dict,queries['question1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a3e5bd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-924ea8ae829c>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cosine_similarity = np.dot(vector1,vector2)/(np.linalg.norm(vector1,ord=2)*np.linalg.norm(vector2,ord=2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query\n",
      "What can one do after MBBS?\n",
      "\n",
      "Ground truth (actual) response\n",
      "What do i do after my MBBS ?\n",
      "\n",
      "Top 5 matching responses\n",
      "What do i do after my MBBS ?\n",
      "What have to Do after MBBS?\n",
      "What can I do after my MBBs?\n",
      "How should I study in MBBS?\n",
      "Is M.B.B.S a good major?\n"
     ]
    }
   ],
   "source": [
    "get_matched_responses(1,responses_tfidf,queries_tfidf,5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1037f7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-924ea8ae829c>:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cosine_similarity = np.dot(vector1,vector2)/(np.linalg.norm(vector1,ord=2)*np.linalg.norm(vector2,ord=2))\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy for matched responses for all queries - sentence embedding by averaging tfidf weighted word vectors\n",
    "top2_tfidf = []\n",
    "top5_tfidf = []\n",
    "\n",
    "for query_index in range(len(queries)):\n",
    "    actual_response_id = queries.loc[query_index,'qid2']\n",
    "    top5_ranked = get_matched_responses(query_index,responses_tfidf,queries_tfidf,5,False)     \n",
    "    if actual_response_id in top5_ranked[:2]:\n",
    "        top2_tfidf.append(1.0)\n",
    "        top5_tfidf.append(1.0)\n",
    "    elif actual_response_id in top5_ranked:\n",
    "        top2_tfidf.append(0.0)\n",
    "        top5_tfidf.append(1.0)    \n",
    "    else:\n",
    "        top2_tfidf.append(0.0)\n",
    "        top5_tfidf.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5365e94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for matched responses in top 2, with averaged tfidf weighted word vectors for sentence embedding: 41.0 %\n",
      "Accuracy for matched responses in top 5, with averaged tfidf weighted word vectors for sentence embedding: 52.0 %\n"
     ]
    }
   ],
   "source": [
    "top2_tfidf_acc = accuracy_score(queries['is_duplicate'], top2_tfidf)\n",
    "top5_tfidf_acc = (accuracy_score(queries['is_duplicate'],top5_tfidf))\n",
    "\n",
    "print('Accuracy for matched responses in top 2, with averaged tfidf weighted word vectors for sentence embedding: {} %'. format(top2_tfidf_acc *100))\n",
    "print('Accuracy for matched responses in top 5, with averaged tfidf weighted word vectors for sentence embedding: {} %'. format(top5_tfidf_acc *100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7744aa53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
