{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "12bd1e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "78912414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 83032: expected 6 fields, saw 7\\n'\n",
      "b'Skipping line 154657: expected 6 fields, saw 7\\n'\n",
      "b'Skipping line 323916: expected 6 fields, saw 7\\n'\n",
      "/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data.tsv', sep='\\t',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7156e816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133273</td>\n",
       "      <td>213221</td>\n",
       "      <td>213222.0</td>\n",
       "      <td>How is the life of a math student? Could you d...</td>\n",
       "      <td>Which level of prepration is enough for the ex...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>402555</td>\n",
       "      <td>536040</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>How do I control my horny emotions?</td>\n",
       "      <td>How do you control your horniness?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360472</td>\n",
       "      <td>364011</td>\n",
       "      <td>490273.0</td>\n",
       "      <td>What causes stool color to change to yellow?</td>\n",
       "      <td>What can cause stool to come out as little balls?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150662</td>\n",
       "      <td>155721</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>What can one do after MBBS?</td>\n",
       "      <td>What do i do after my MBBS ?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183004</td>\n",
       "      <td>279958</td>\n",
       "      <td>279959.0</td>\n",
       "      <td>Where can I find a power outlet for my laptop ...</td>\n",
       "      <td>Would a second airport in Sydney, Australia be...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1      qid2  \\\n",
       "0  133273  213221  213222.0   \n",
       "1  402555  536040  536041.0   \n",
       "2  360472  364011  490273.0   \n",
       "3  150662  155721    7256.0   \n",
       "4  183004  279958  279959.0   \n",
       "\n",
       "                                           question1  \\\n",
       "0  How is the life of a math student? Could you d...   \n",
       "1                How do I control my horny emotions?   \n",
       "2       What causes stool color to change to yellow?   \n",
       "3                        What can one do after MBBS?   \n",
       "4  Where can I find a power outlet for my laptop ...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  Which level of prepration is enough for the ex...           0.0  \n",
       "1                 How do you control your horniness?           1.0  \n",
       "2  What can cause stool to come out as little balls?           0.0  \n",
       "3                       What do i do after my MBBS ?           1.0  \n",
       "4  Would a second airport in Sydney, Australia be...           0.0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "66b11bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 363192 entries, 0 to 363191\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            363192 non-null  object \n",
      " 1   qid1          363192 non-null  object \n",
      " 2   qid2          363185 non-null  float64\n",
      " 3   question1     363181 non-null  object \n",
      " 4   question2     363180 non-null  object \n",
      " 5   is_duplicate  363180 non-null  float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1bacfd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0, subset=('question1','question2','is_duplicate' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d3ef301a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 363177 entries, 0 to 363191\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            363177 non-null  object \n",
      " 1   qid1          363177 non-null  object \n",
      " 2   qid2          363177 non-null  float64\n",
      " 3   question1     363177 non-null  object \n",
      " 4   question2     363177 non-null  object \n",
      " 5   is_duplicate  363177 non-null  float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 19.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d7d36615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#lower casing\n",
    "def lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "#remove numbers\n",
    "def remove_numbers(text):\n",
    "    output = re.sub(r'\\d+', '', text)\n",
    "    return output\n",
    "\n",
    "# remove punctuation\n",
    "import string\n",
    "def remove_punctuation(text):\n",
    "    text_p = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_p\n",
    "\n",
    "#tokenize text\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    words = word_tokenize(text)\n",
    "    return words\n",
    "\n",
    "#remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    filtered_words = [word for word in text if word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "#stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    stemmed = [stemmer.stem(word) for word in text]\n",
    "    return stemmed\n",
    "\n",
    "# Lemmatize with POS Tag\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemmatized = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in text]\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3cd7bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def preprocess(self,df_column, steps):\n",
    "        self.df_column = df_column\n",
    "        self.steps = steps\n",
    "    \n",
    "        if 'lower_case' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: lower_case(x))\n",
    "        \n",
    "        \n",
    "        if 'remove_numbers' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: remove_numbers(x))\n",
    "        \n",
    "        if 'remove_punctuation' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: remove_punctuation(x))           \n",
    "        \n",
    "        if 'tokenize' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: tokenize(x))\n",
    "        \n",
    "        if 'stopwords' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: remove_stopwords(x))\n",
    "        \n",
    "        if 'stemming' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: stem_words(x))\n",
    "            \n",
    "        if 'lemmatize' in self.steps:\n",
    "            self.df_column = self.df_column.apply(lambda x: lemmatize(x))    \n",
    "            \n",
    "        return self.df_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b522311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = ['lower_case','remove_numbers','remove_punctuation',\n",
    "        'tokenize','stopwords','lemmatize']\n",
    "processor = Preprocessor()\n",
    "df['question1'] = processor.preprocess(df['question1'] ,steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "32966a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question2'] = processor.preprocess(df['question2'] ,steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bdb147fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 363177 entries, 0 to 363176\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   index         363177 non-null  int64  \n",
      " 1   id            363177 non-null  object \n",
      " 2   qid1          363177 non-null  object \n",
      " 3   qid2          363177 non-null  float64\n",
      " 4   question1     363177 non-null  object \n",
      " 5   question2     363177 non-null  object \n",
      " 6   is_duplicate  363177 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 19.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f38abb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>133273</td>\n",
       "      <td>213221</td>\n",
       "      <td>213222.0</td>\n",
       "      <td>[life, math, student, could, describe, experie...</td>\n",
       "      <td>[level, prepration, enough, exam, jlpt]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>402555</td>\n",
       "      <td>536040</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>[control, horny, emotion]</td>\n",
       "      <td>[control, horniness]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>360472</td>\n",
       "      <td>364011</td>\n",
       "      <td>490273.0</td>\n",
       "      <td>[cause, stool, color, change, yellow]</td>\n",
       "      <td>[cause, stool, come, little, ball]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>150662</td>\n",
       "      <td>155721</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>[one, mbbs]</td>\n",
       "      <td>[mbbs]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>183004</td>\n",
       "      <td>279958</td>\n",
       "      <td>279959.0</td>\n",
       "      <td>[find, power, outlet, laptop, melbourne, airport]</td>\n",
       "      <td>[would, second, airport, sydney, australia, ne...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      id    qid1      qid2  \\\n",
       "0      0  133273  213221  213222.0   \n",
       "1      1  402555  536040  536041.0   \n",
       "2      2  360472  364011  490273.0   \n",
       "3      3  150662  155721    7256.0   \n",
       "4      4  183004  279958  279959.0   \n",
       "\n",
       "                                           question1  \\\n",
       "0  [life, math, student, could, describe, experie...   \n",
       "1                          [control, horny, emotion]   \n",
       "2              [cause, stool, color, change, yellow]   \n",
       "3                                        [one, mbbs]   \n",
       "4  [find, power, outlet, laptop, melbourne, airport]   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0            [level, prepration, enough, exam, jlpt]           0.0  \n",
       "1                               [control, horniness]           1.0  \n",
       "2                 [cause, stool, come, little, ball]           0.0  \n",
       "3                                             [mbbs]           1.0  \n",
       "4  [would, second, airport, sydney, australia, ne...           0.0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8caf547a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56588"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2vocab = df['question2'].tolist()\n",
    "q2vocab = [item for sublist in q2vocab for item in sublist]\n",
    "q2vocab = list(set(q2vocab))\n",
    "len(q2vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0dbf2193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cupcake',\n",
       "  [85889.0,\n",
       "   36228.0,\n",
       "   11269.0,\n",
       "   195462.0,\n",
       "   359051.0,\n",
       "   2574.0,\n",
       "   2575.0,\n",
       "   209425.0,\n",
       "   442524.0,\n",
       "   3487.0,\n",
       "   43042.0,\n",
       "   507955.0,\n",
       "   570.0,\n",
       "   571.0,\n",
       "   151358.0,\n",
       "   99651.0,\n",
       "   135372.0,\n",
       "   88918.0,\n",
       "   207831.0,\n",
       "   207830.0,\n",
       "   18273.0,\n",
       "   16227.0,\n",
       "   16228.0,\n",
       "   5867.0,\n",
       "   227955.0,\n",
       "   122997.0,\n",
       "   32373.0,\n",
       "   40441.0]),\n",
       " ('galway', [346536.0, 185355.0, 250990.0]),\n",
       " ('declassify', [29364.0]),\n",
       " ('peach',\n",
       "  [322528.0,\n",
       "   241384.0,\n",
       "   516055.0,\n",
       "   382099.0,\n",
       "   456023.0,\n",
       "   112922.0,\n",
       "   18492.0,\n",
       "   532671.0]),\n",
       " ('auntuncle', [321940.0])]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define function \n",
    "def get_Doc_ids(vocabulary_list,dataframe,tokens_col_name, id_col_name):\n",
    "    Doc_ids = {}      #initialise empty document frequency dictionary\n",
    "    \n",
    "    #for each word in vocabulary, create key:value pair, with an empty list as value\n",
    "    for word in vocabulary_list:\n",
    "        Doc_ids[word] = [] \n",
    "        \n",
    "    #for each word in DF, add the id of question2 where it appears. Create a set to avoid duplicate ids\n",
    "    for i in range(len(dataframe)):\n",
    "        for word in dataframe.loc[i,tokens_col_name]:\n",
    "            Doc_ids[word].append(dataframe[id_col_name][i])\n",
    "    for word in Doc_ids.keys():\n",
    "        Doc_ids[word] = list(set(Doc_ids[word]))\n",
    "        #DF[word]  =len(DF[word])\n",
    "        \n",
    "    return Doc_ids\n",
    "\n",
    "Doc_ids = get_Doc_ids(q2vocab,df,'question2','qid2')\n",
    "list(Doc_ids.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "33e58f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary - word: list of doc_ids\n",
    "Word_Doc_ids = {}\n",
    "for word in q2vocab:\n",
    "    Word_Doc_ids[word] = []\n",
    "for i in range(len(df)):\n",
    "    for word in df.loc[i,'question2']:\n",
    "        Word_Doc_ids[word].append(df.loc[i,'qid2'])\n",
    "\n",
    "#create set to drop duplicate values of doc_ids\n",
    "for word in q2vocab:\n",
    "    Word_Doc_ids[word] = list(set(Word_Doc_ids[word]))\n",
    "# for i in range(len(q2vocab)):\n",
    "#     if q2vocab[i] in df.loc[i,'question2']:\n",
    "#         Word_Doc_ids[q2vocab[i]].append(df.loc[i,'qid2'])\n",
    "# for word in q2vocab:        \n",
    "#     Word_Doc_ids[word] = list(set(Word_Doc_ids[word]))        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aa024eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cupcake',\n",
       "  [85889.0,\n",
       "   36228.0,\n",
       "   11269.0,\n",
       "   195462.0,\n",
       "   359051.0,\n",
       "   2574.0,\n",
       "   2575.0,\n",
       "   209425.0,\n",
       "   442524.0,\n",
       "   3487.0,\n",
       "   43042.0,\n",
       "   507955.0,\n",
       "   570.0,\n",
       "   571.0,\n",
       "   151358.0,\n",
       "   99651.0,\n",
       "   135372.0,\n",
       "   88918.0,\n",
       "   207831.0,\n",
       "   207830.0,\n",
       "   18273.0,\n",
       "   16227.0,\n",
       "   16228.0,\n",
       "   5867.0,\n",
       "   227955.0,\n",
       "   122997.0,\n",
       "   32373.0,\n",
       "   40441.0]),\n",
       " ('galway', [346536.0, 185355.0, 250990.0])]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Word_Doc_ids.items())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "03d6a463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cupcake', 9417.965517241379),\n",
       " ('galway', 68280.25),\n",
       " ('declassify', 136560.5),\n",
       " ('peach', 30346.777777777777),\n",
       " ('auntuncle', 136560.5)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create Inverse Document_frequency (IDF) dictionary\n",
    "N = df['qid2'].nunique()\n",
    "print(N)\n",
    "\n",
    "IDF = {}\n",
    "for word in Doc_ids.keys():\n",
    "    IDF[word] = N/(len(Word_Doc_ids[word])+1)\n",
    "list(IDF.items())[:5]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "56e8a5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q2_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>133273</td>\n",
       "      <td>213221</td>\n",
       "      <td>213222.0</td>\n",
       "      <td>[life, math, student, could, describe, experie...</td>\n",
       "      <td>[level, prepration, enough, exam, jlpt]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>402555</td>\n",
       "      <td>536040</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>[control, horny, emotion]</td>\n",
       "      <td>[control, horniness]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      id    qid1      qid2  \\\n",
       "0      0  133273  213221  213222.0   \n",
       "1      1  402555  536040  536041.0   \n",
       "\n",
       "                                           question1  \\\n",
       "0  [life, math, student, could, describe, experie...   \n",
       "1                          [control, horny, emotion]   \n",
       "\n",
       "                                 question2  is_duplicate  q2_len  \n",
       "0  [level, prepration, enough, exam, jlpt]           0.0       5  \n",
       "1                     [control, horniness]           1.0       2  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['q2_len'] = df['question2'].apply(lambda x: len(x) )\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a236517c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(213222.0, ['level', 'prepration', 'enough', 'exam', 'jlpt']),\n",
       " (536041.0, ['control', 'horniness'])]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary - doc_id: words\n",
    "doc_words = dict(zip(df['qid2'],df['question2']))\n",
    "# tf_lists = {}\n",
    "# for word in q2vocab:\n",
    "#     word_tf = []\n",
    "#     for doc in Doc_ids[word]:\n",
    "#         tf = doc_words[doc].count(word)/len(doc_words[doc])\n",
    "#         word_tf.append(tf)\n",
    "#     tf_lists[word] = word_tf \n",
    "    \n",
    "# list(tf_lists.items())[:5] \n",
    "list(doc_words.items())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e9531dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary where keys are words in the vocab, \n",
    "#values are dictionary of key:values as doc_id:tf for corresponding word\n",
    "#nested dictionary - word: {{doc_id1: tf}, {doc_id2: tf}, ....}\n",
    "inverted_tf = {}\n",
    "for word in q2vocab:\n",
    "    word_tf = {}\n",
    "    for doc in Word_Doc_ids[word]:\n",
    "        tf = doc_words[doc].count(word)/len(doc_words[doc])\n",
    "        word_tf[doc] = tf\n",
    "    inverted_tf[word] = word_tf   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "eb32b20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cupcake',\n",
       " {85889.0: 0.1111111111111111,\n",
       "  36228.0: 0.125,\n",
       "  11269.0: 0.16666666666666666,\n",
       "  195462.0: 0.1111111111111111,\n",
       "  359051.0: 0.16666666666666666,\n",
       "  2574.0: 0.16666666666666666,\n",
       "  2575.0: 0.1111111111111111,\n",
       "  209425.0: 0.25,\n",
       "  442524.0: 0.16666666666666666,\n",
       "  3487.0: 0.16666666666666666,\n",
       "  43042.0: 0.125,\n",
       "  507955.0: 0.2,\n",
       "  570.0: 0.14285714285714285,\n",
       "  571.0: 0.2,\n",
       "  151358.0: 0.16666666666666666,\n",
       "  99651.0: 0.25,\n",
       "  135372.0: 0.14285714285714285,\n",
       "  88918.0: 0.14285714285714285,\n",
       "  207831.0: 0.2,\n",
       "  207830.0: 0.3333333333333333,\n",
       "  18273.0: 0.16666666666666666,\n",
       "  16227.0: 0.3333333333333333,\n",
       "  16228.0: 0.3333333333333333,\n",
       "  5867.0: 0.16666666666666666,\n",
       "  227955.0: 0.16666666666666666,\n",
       "  122997.0: 0.14285714285714285,\n",
       "  32373.0: 0.14285714285714285,\n",
       "  40441.0: 0.16666666666666666})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(inverted_tf.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8884a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_first = []\n",
    "# first = list(inverted_tf['header'].items()) \n",
    "# for tup in first:\n",
    "#     tup = list(tup)\n",
    "#     tfidf = tup[1]*np.log10(IDF['header'])\n",
    "#     tup[1] = tfidf\n",
    "#     tfidf_first.append(tup)\n",
    "# tfidf_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "be2b845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary where keys are words in the vocab, \n",
    "#values are dictinary of key:values as doc_id:tfidf for corresponding word\n",
    "#nested dictionary - word: {{doc_id1: tf}, {doc_id2: tf}, ....}\n",
    "inverted_tfidf = {}\n",
    "for word in q2vocab:\n",
    "    doc_tfidfs = []\n",
    "    for tup in list(inverted_tf[word].items()):\n",
    "        tup = list(tup)\n",
    "        tfidf = tup[1]*np.log10(IDF[word])\n",
    "        tup[1] = tfidf\n",
    "        doc_tfidfs.append(tup)\n",
    "    inverted_tfidf[word] = doc_tfidfs  \n",
    "\n",
    "# for i in range(len(inverted_tfidf)):\n",
    "#     inverted_tfidf[q2vocab[i]] = [dict([[x[0],x[1]]])\n",
    "#                                 for x in inverted_tfidf[q2vocab[i]]]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4827c290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cupcake',\n",
       " [[85889.0, 0.44155078844356815],\n",
       "  [36228.0, 0.4967446369990142],\n",
       "  [11269.0, 0.6623261826653523],\n",
       "  [195462.0, 0.44155078844356815],\n",
       "  [359051.0, 0.6623261826653523],\n",
       "  [2574.0, 0.6623261826653523],\n",
       "  [2575.0, 0.44155078844356815],\n",
       "  [209425.0, 0.9934892739980284],\n",
       "  [442524.0, 0.6623261826653523],\n",
       "  [3487.0, 0.6623261826653523],\n",
       "  [43042.0, 0.4967446369990142],\n",
       "  [507955.0, 0.7947914191984228],\n",
       "  [570.0, 0.5677081565703019],\n",
       "  [571.0, 0.7947914191984228],\n",
       "  [151358.0, 0.6623261826653523],\n",
       "  [99651.0, 0.9934892739980284],\n",
       "  [135372.0, 0.5677081565703019],\n",
       "  [88918.0, 0.5677081565703019],\n",
       "  [207831.0, 0.7947914191984228],\n",
       "  [207830.0, 1.3246523653307045],\n",
       "  [18273.0, 0.6623261826653523],\n",
       "  [16227.0, 1.3246523653307045],\n",
       "  [16228.0, 1.3246523653307045],\n",
       "  [5867.0, 0.6623261826653523],\n",
       "  [227955.0, 0.6623261826653523],\n",
       "  [122997.0, 0.5677081565703019],\n",
       "  [32373.0, 0.5677081565703019],\n",
       "  [40441.0, 0.6623261826653523]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(inverted_tfidf.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "96eebb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(inverted_tfidf)):\n",
    "    inverted_tfidf[q2vocab[i]] = {x[0]:x[1] for x in inverted_tfidf[q2vocab[i]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e3a07dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cupcake',\n",
       " {85889.0: 0.44155078844356815,\n",
       "  36228.0: 0.4967446369990142,\n",
       "  11269.0: 0.6623261826653523,\n",
       "  195462.0: 0.44155078844356815,\n",
       "  359051.0: 0.6623261826653523,\n",
       "  2574.0: 0.6623261826653523,\n",
       "  2575.0: 0.44155078844356815,\n",
       "  209425.0: 0.9934892739980284,\n",
       "  442524.0: 0.6623261826653523,\n",
       "  3487.0: 0.6623261826653523,\n",
       "  43042.0: 0.4967446369990142,\n",
       "  507955.0: 0.7947914191984228,\n",
       "  570.0: 0.5677081565703019,\n",
       "  571.0: 0.7947914191984228,\n",
       "  151358.0: 0.6623261826653523,\n",
       "  99651.0: 0.9934892739980284,\n",
       "  135372.0: 0.5677081565703019,\n",
       "  88918.0: 0.5677081565703019,\n",
       "  207831.0: 0.7947914191984228,\n",
       "  207830.0: 1.3246523653307045,\n",
       "  18273.0: 0.6623261826653523,\n",
       "  16227.0: 1.3246523653307045,\n",
       "  16228.0: 1.3246523653307045,\n",
       "  5867.0: 0.6623261826653523,\n",
       "  227955.0: 0.6623261826653523,\n",
       "  122997.0: 0.5677081565703019,\n",
       "  32373.0: 0.5677081565703019,\n",
       "  40441.0: 0.6623261826653523})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(inverted_tfidf.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8a6c3ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[control, horny, emotion]</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>[control, horniness]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[one, mbbs]</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>[mbbs]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>[best, self, help, book, read, change, life]</td>\n",
       "      <td>787.0</td>\n",
       "      <td>[top, self, help, book, read]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>[hillary, clinton, policy, towards, india, bec...</td>\n",
       "      <td>177376.0</td>\n",
       "      <td>[hilary, clinton, policy, towards, india, beco...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>[best, book, study, tensor, general, relativit...</td>\n",
       "      <td>22333.0</td>\n",
       "      <td>[best, book, tensor, calculus]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          question1      qid2  \\\n",
       "0      1                          [control, horny, emotion]  536041.0   \n",
       "1      3                                        [one, mbbs]    7256.0   \n",
       "2      7       [best, self, help, book, read, change, life]     787.0   \n",
       "3     11  [hillary, clinton, policy, towards, india, bec...  177376.0   \n",
       "4     13  [best, book, study, tensor, general, relativit...   22333.0   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0                               [control, horniness]           1.0  \n",
       "1                                             [mbbs]           1.0  \n",
       "2                      [top, self, help, book, read]           1.0  \n",
       "3  [hilary, clinton, policy, towards, india, beco...           1.0  \n",
       "4                     [best, book, tensor, calculus]           1.0  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = df[df['is_duplicate'] == 1][:100]\n",
    "queries = queries[['question1','qid2','question2', 'is_duplicate']]\n",
    "queries = queries.reset_index()\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3499163b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "aea9278a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['control', 'horny', 'emotion']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[355257.0, 344642.0, 348571.0, 42047.0, 132587.0]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def ranked_docs(query, inverted_file):\n",
    "    counter_objects = []\n",
    "    for word in query:\n",
    "        if word in inverted_file.keys():\n",
    "            counter_objects.append(Counter(inverted_file[word]))\n",
    "            combined = sum(counter_objects,Counter())\n",
    "            ranked_docs = sorted(combined, key = combined.get, reverse=True)\n",
    "    return ranked_docs \n",
    "query = queries.loc[0,'question1']\n",
    "#ranked_docs(query,inverted_tfidf)\n",
    "print(query)\n",
    "ranked_docs(query,inverted_tfidf)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1d194229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[355257.0, 344642.0, 348571.0, 42047.0, 132587.0]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ranked_docs2(query,inverted_file):\n",
    "    counter_objects = []\n",
    "    for word in query:\n",
    "        if word in inverted_file.keys():\n",
    "            counter_objects.append(inverted_file[word])\n",
    "    c = Counter()\n",
    "    for cob in counter_objects:\n",
    "        c.update(cob)\n",
    "    ranked_docs = sorted(c, key = c.get, reverse=True) \n",
    "    return ranked_docs,counter_objects\n",
    "\n",
    "ranked_docs2,_ = ranked_docs2(query,inverted_tfidf)\n",
    "ranked_docs2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d3ee8054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[355257.0, 344642.0, 348571.0, 42047.0, 132587.0]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_objects = []\n",
    "for word in query:\n",
    "    if word in inverted_tfidf.keys():\n",
    "        counter_objects.append(Counter(inverted_tfidf[word]))\n",
    "        combined = sum(counter_objects,Counter())\n",
    "        ranked_docs = sorted(combined, key = combined.get, reverse=True)\n",
    "ranked_docs[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "fc3e114d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[355257.0, 344642.0, 348571.0, 42047.0, 132587.0]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_objects = []\n",
    "counter_objects.append(inverted_tfidf['control'])\n",
    "counter_objects.append(inverted_tfidf['horny'])\n",
    "counter_objects.append(inverted_tfidf['emotion'])\n",
    "counter_objects[0]\n",
    "c = Counter()\n",
    "for cob in counter_objects:\n",
    "    c.update(cob)\n",
    "ranked_docs = sorted(c, key = c.get, reverse=True)\n",
    "ranked_docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1b3aa2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q2_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322413</th>\n",
       "      <td>322425</td>\n",
       "      <td>242931</td>\n",
       "      <td>310574</td>\n",
       "      <td>355257.0</td>\n",
       "      <td>[always, horny]</td>\n",
       "      <td>[horny]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index      id    qid1      qid2        question1 question2  \\\n",
       "322413  322425  242931  310574  355257.0  [always, horny]   [horny]   \n",
       "\n",
       "        is_duplicate  q2_len  \n",
       "322413           1.0       1  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['qid2'] == 355257.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "19bff53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>top5_pred</th>\n",
       "      <th>top2_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[control, horny, emotion]</td>\n",
       "      <td>536041.0</td>\n",
       "      <td>[control, horniness]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[one, mbbs]</td>\n",
       "      <td>7256.0</td>\n",
       "      <td>[mbbs]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>[best, self, help, book, read, change, life]</td>\n",
       "      <td>787.0</td>\n",
       "      <td>[top, self, help, book, read]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>[hillary, clinton, policy, towards, india, bec...</td>\n",
       "      <td>177376.0</td>\n",
       "      <td>[hilary, clinton, policy, towards, india, beco...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>[best, book, study, tensor, general, relativit...</td>\n",
       "      <td>22333.0</td>\n",
       "      <td>[best, book, tensor, calculus]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                          question1      qid2  \\\n",
       "0      1                          [control, horny, emotion]  536041.0   \n",
       "1      3                                        [one, mbbs]    7256.0   \n",
       "2      7       [best, self, help, book, read, change, life]     787.0   \n",
       "3     11  [hillary, clinton, policy, towards, india, bec...  177376.0   \n",
       "4     13  [best, book, study, tensor, general, relativit...   22333.0   \n",
       "\n",
       "                                           question2  is_duplicate  top5_pred  \\\n",
       "0                               [control, horniness]           1.0        0.0   \n",
       "1                                             [mbbs]           1.0        1.0   \n",
       "2                      [top, self, help, book, read]           1.0        0.0   \n",
       "3  [hilary, clinton, policy, towards, india, beco...           1.0        0.0   \n",
       "4                     [best, book, tensor, calculus]           1.0        0.0   \n",
       "\n",
       "   top2_pred  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(queries)):\n",
    "    query = queries.loc[i,'question1']\n",
    "    ranked = ranked_docs(query, inverted_tfidf)\n",
    "    if queries.loc[i,'qid2'] in ranked[:2]:\n",
    "        queries.loc[i,'top5_pred'] = 1.0\n",
    "        queries.loc[i,'top2_pred'] = 1.0\n",
    "    elif queries.loc[i,'qid2'] in ranked[:5]:\n",
    "        queries.loc[i,'top5_pred'] = 1.0\n",
    "        queries.loc[i,'top2_pred'] = 0.0\n",
    "    else:\n",
    "        queries.loc[i,'top5_pred'] = 0.0\n",
    "        queries.loc[i,'top2_pred'] = 0.0\n",
    "    \n",
    "    \n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b6b30800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(queries['is_duplicate'],queries['top2_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0e22237f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(queries['is_duplicate'],queries['top5_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8e805817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best', 'self', 'help', 'book', 'read', 'change', 'life']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query2 = queries.loc[2,'question1']\n",
    "query2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8426f1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[203474.0, 157424.0, 26371.0, 125925.0, 110004.0]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_docs(query2,inverted_tfidf)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3e0e15da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1539595891485446"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_tfidf['help'][203474.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "03558b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_objects = []\n",
    "for word in query2:\n",
    "    \n",
    "    if word in inverted_tfidf.keys():\n",
    "        counter_objects.append(inverted_tfidf[word])\n",
    "\n",
    "c = Counter()\n",
    "for cob in counter_objects:\n",
    "    c.update(cob)\n",
    "    \n",
    "#combined = sum(counter_objects,Counter())\n",
    "ranked_docs = sorted(c, key = c.get, reverse=True)\n",
    "ranked_docs[:5]\n",
    "len(counter_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4f5e8191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1438"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_objects = []\n",
    "len(Counter(inverted_tfidf['top']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d393afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dicts = []\n",
    "for word in query:\n",
    "    list_dicts.append(Counter(inverted_tfidf[word]))\n",
    "len(list_dicts)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3438ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dict = sum(list_dicts, Counter())\n",
    "max(merged_dict, key=merged_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1eb47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['qid2'] == 355257.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed7e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = sorted(merged_dict, key=merged_dict.get, reverse=True)\n",
    "ranked[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "9592da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "train_questions = list(df['question2'])\n",
    "def dummy(text):\n",
    "    return text\n",
    "tf = TfidfVectorizer(tokenizer=dummy,preprocessor=dummy, lowercase=False)\n",
    "X_train = tf.fit_transform(train_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1b65cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainT = X_train.T.todok()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1acc5a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56588, 363177)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XtrainT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a1c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(tuple(i) for i in train_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df['qid2'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d680906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
